{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYmeUmu95hykVWFaPv+DWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abolfazlaghdaee/LLM_journey/blob/main/Using_pretrained_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model Hub makes selecting the appropriate model simple, so that using it in any downstream library can be done in a few lines of code. Let’s take a look at how to actually use one of these models, and how to contribute back to the community."
      ],
      "metadata": {
        "id": "ZkD22swzHNJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "SbOU5o4YHOYw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"fill-mask\", model=\"google-bert/bert-base-multilingual-cased\")\n",
        "\n",
        "results = pipe(\"سلام [MASK] شما چطوراست؟\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Kj11QzHay3",
        "outputId": "f57196bc-ed1b-4037-dec2-367176c7920a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqUiSqHgHgQw",
        "outputId": "1e3af07d-ba5c-4f53-c007-9ecf72894ddc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3520471751689911,\n",
              "  'token': 131,\n",
              "  'token_str': ':',\n",
              "  'sequence': 'سلام : شما چطوراست ؟'},\n",
              " {'score': 0.12845134735107422,\n",
              "  'token': 117,\n",
              "  'token_str': ',',\n",
              "  'sequence': 'سلام, شما چطوراست ؟'},\n",
              " {'score': 0.061107706278562546,\n",
              "  'token': 106,\n",
              "  'token_str': '!',\n",
              "  'sequence': 'سلام! شما چطوراست ؟'},\n",
              " {'score': 0.03578856959939003,\n",
              "  'token': 10327,\n",
              "  'token_str': 'به',\n",
              "  'sequence': 'سلام به شما چطوراست ؟'},\n",
              " {'score': 0.03459658473730087,\n",
              "  'token': 118,\n",
              "  'token_str': '-',\n",
              "  'sequence': 'سلام - شما چطوراست ؟'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, loading a model within a pipeline is extremely simple. The only thing you need to watch out for is that the chosen checkpoint is suitable for the task it’s going to be used for. For example, here we are loading the camembert-base checkpoint in the fill-mask pipeline, which is completely fine. But if we were to load this checkpoint in the text-classification pipeline, the results would not make any sense because the head of camembert-base is not suitable for this task!"
      ],
      "metadata": {
        "id": "LpFoRPsjJUjN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "scRnfdaxHoBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}